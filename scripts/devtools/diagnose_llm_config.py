#!/usr/bin/env python3
"""è¯Šæ–­å¹¶ä¿®å¤ LLM é…ç½®ä¸­çš„ NULL max_tokens"""

import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° Python è·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from AICrews.database.db_manager import DBManager
from AICrews.database.models.llm import (
    UserLLMConfig,
    UserModelConfig,
    CrewAgentLLMConfig,
    LLMModel
)
from sqlalchemy import select


def diagnose_null_max_tokens():
    """è¯Šæ–­æ‰€æœ‰å¯èƒ½å¯¼è‡´ NoneType æ¯”è¾ƒé”™è¯¯çš„é…ç½®"""
    db = DBManager()

    print("ğŸ” æ£€æŸ¥ LLM é…ç½®ä¸­çš„ NULL max_tokens...\n")

    with db.get_session() as session:
        # æ£€æŸ¥ UserLLMConfig
        print("1ï¸âƒ£ æ£€æŸ¥ UserLLMConfig.default_max_tokens")
        stmt = select(UserLLMConfig).where(UserLLMConfig.default_max_tokens.is_(None))
        configs = session.execute(stmt).scalars().all()
        print(f"   å‘ç° {len(configs)} ä¸ªé…ç½®çš„ default_max_tokens ä¸º NULL")
        for cfg in configs:
            print(f"   - ID: {cfg.id}, Name: {cfg.config_name}, Provider: {cfg.provider_id}")

        # æ£€æŸ¥ UserModelConfig
        print("\n2ï¸âƒ£ æ£€æŸ¥ UserModelConfig.max_tokens")
        stmt = select(UserModelConfig).where(UserModelConfig.max_tokens.is_(None))
        model_configs = session.execute(stmt).scalars().all()
        print(f"   å‘ç° {len(model_configs)} ä¸ªé…ç½®çš„ max_tokens ä¸º NULL")
        for cfg in model_configs:
            stmt_model = select(LLMModel).where(LLMModel.id == cfg.model_id)
            model = session.execute(stmt_model).scalar_one_or_none()
            print(f"   - ID: {cfg.id}, Model: {model.model_key if model else 'Unknown'}, User: {cfg.user_id}")

        # æ£€æŸ¥ CrewAgentLLMConfig
        print("\n3ï¸âƒ£ æ£€æŸ¥ CrewAgentLLMConfig.max_tokens")
        stmt = select(CrewAgentLLMConfig).where(CrewAgentLLMConfig.max_tokens.is_(None))
        agent_configs = session.execute(stmt).scalars().all()
        print(f"   å‘ç° {len(agent_configs)} ä¸ªé…ç½®çš„ max_tokens ä¸º NULL")
        for cfg in agent_configs:
            print(f"   - ID: {cfg.id}, Crew: {cfg.crew_name}, Agent: {cfg.agent_role}")

        print("\n" + "="*60)
        print("ğŸ’¡ å»ºè®®:")
        print("   - å¦‚æœå‘ç° NULL é…ç½®,è¿è¡Œ fix_null_max_tokens() è‡ªåŠ¨ä¿®å¤")
        print("   - æˆ–æ‰‹åŠ¨åœ¨æ•°æ®åº“ä¸­è®¾ç½®åˆç†çš„é»˜è®¤å€¼(å¦‚ 4096)")
        print("="*60)


def fix_null_max_tokens(default_value: int = 4096, dry_run: bool = True):
    """ä¿®å¤æ‰€æœ‰ NULL max_tokens é…ç½®

    Args:
        default_value: é»˜è®¤çš„ max_tokens å€¼
        dry_run: å¦‚æœä¸º True,åªæ˜¾ç¤ºå°†è¦ä¿®æ”¹çš„å†…å®¹,ä¸å®é™…æ‰§è¡Œ
    """
    db = DBManager()

    mode = "ğŸ” DRY RUN æ¨¡å¼" if dry_run else "âœï¸ æ‰§è¡Œä¿®å¤"
    print(f"{mode} - è®¾ç½®é»˜è®¤å€¼: {default_value}\n")

    with db.get_session() as session:
        # ä¿®å¤ UserLLMConfig
        stmt = select(UserLLMConfig).where(UserLLMConfig.default_max_tokens.is_(None))
        configs = session.execute(stmt).scalars().all()
        print(f"1ï¸âƒ£ å°†ä¿®å¤ {len(configs)} ä¸ª UserLLMConfig")
        if not dry_run:
            for cfg in configs:
                cfg.default_max_tokens = default_value
            session.commit()
            print("   âœ… å·²æäº¤")

        # ä¿®å¤ UserModelConfig
        stmt = select(UserModelConfig).where(UserModelConfig.max_tokens.is_(None))
        model_configs = session.execute(stmt).scalars().all()
        print(f"\n2ï¸âƒ£ å°†ä¿®å¤ {len(model_configs)} ä¸ª UserModelConfig")
        if not dry_run:
            for cfg in model_configs:
                cfg.max_tokens = default_value
            session.commit()
            print("   âœ… å·²æäº¤")

        # ä¿®å¤ CrewAgentLLMConfig
        stmt = select(CrewAgentLLMConfig).where(CrewAgentLLMConfig.max_tokens.is_(None))
        agent_configs = session.execute(stmt).scalars().all()
        print(f"\n3ï¸âƒ£ å°†ä¿®å¤ {len(agent_configs)} ä¸ª CrewAgentLLMConfig")
        if not dry_run:
            for cfg in agent_configs:
                cfg.max_tokens = default_value
            session.commit()
            print("   âœ… å·²æäº¤")

    if dry_run:
        print("\nâš ï¸ DRY RUN å®Œæˆ - æœªå®é™…ä¿®æ”¹æ•°æ®")
        print("   è¿è¡Œ fix_null_max_tokens(dry_run=False) æ‰§è¡Œå®é™…ä¿®å¤")
    else:
        print("\nâœ… ä¿®å¤å®Œæˆ!")


if __name__ == "__main__":
    import argparse

    parser = argparse.ArgumentParser(description="è¯Šæ–­å’Œä¿®å¤ LLM é…ç½®ä¸­çš„ NULL max_tokens")
    parser.add_argument("--diagnose", action="store_true", help="ä»…è¯Šæ–­é—®é¢˜,ä¸ä¿®å¤")
    parser.add_argument("--fix", action="store_true", help="æ‰§è¡Œä¿®å¤")
    parser.add_argument("--dry-run", dest="dry_run", action="store_true", default=True, help="DRY RUN æ¨¡å¼(é»˜è®¤)")
    parser.add_argument("--no-dry-run", dest="dry_run", action="store_false", help="å®é™…æ‰§è¡Œä¿®å¤")
    parser.add_argument("--default-value", type=int, default=4096, help="é»˜è®¤ max_tokens å€¼(é»˜è®¤4096)")

    args = parser.parse_args()

    if args.fix:
        fix_null_max_tokens(
            default_value=args.default_value,
            dry_run=args.dry_run
        )
    else:
        diagnose_null_max_tokens()
