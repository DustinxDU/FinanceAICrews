import os
import pandas as pd
import json
from contextlib import asynccontextmanager
from datetime import datetime, timedelta
from typing import List, Dict, Optional, Any, AsyncGenerator
from sqlalchemy import create_engine, select, text, and_, or_
from sqlalchemy.orm import sessionmaker
from sqlalchemy.ext.asyncio import create_async_engine, AsyncSession, async_sessionmaker
from sqlalchemy.dialects.postgresql import insert as pg_insert

from .models import (
    Base, 
    StockPrice, 
    FundamentalData,
    FinancialStatement,
    TechnicalIndicator,
    MarketNews,
    InsiderActivity,
    AnalysisReport, 
    TradingLesson
)

from AICrews.utils import monitor
from AICrews.observability.logging import get_module_logger, LogModule

logger = get_module_logger(LogModule.DATABASE)
from AICrews.utils.exceptions import DatabaseException, ConfigException

# å°è¯•ä»ç¯å¢ƒå˜é‡è·å–æ•°æ®åº“é…ç½®
DB_URL = os.getenv("DATABASE_URL")

# å¦‚æœæ²¡æœ‰è®¾ç½® DATABASE_URLï¼Œåœ¨å¼€å‘ç¯å¢ƒä¸‹å°è¯•æ„é€ ä¸€ä¸ªé»˜è®¤åœ°å€
# ç”Ÿäº§ç¯å¢ƒä¸‹å¿…é¡»é€šè¿‡ç¯å¢ƒå˜é‡æä¾›
if not DB_URL:
    logger.warning("DATABASE_URL not set in environment. Database features will be unavailable.")



class DBManager:
    _instance = None

    def __new__(cls):
        if cls._instance is None:
            cls._instance = super(DBManager, cls).__new__(cls)
            cls._instance.engine = None
            cls._instance.SessionLocal = None
        return cls._instance

    def _ensure_engine(self):
        """æ‡’åŠ è½½åˆ›å»ºæ•°æ®åº“ Engine å’Œ Sessionï¼Œé¿å…å¯¼å…¥å³è¿æ¥"""
        if self.engine is not None and self.SessionLocal is not None:
            return

        if not DB_URL:
            raise ConfigException("DATABASE_URL æœªé…ç½®ï¼Œæ— æ³•åˆå§‹åŒ–æ•°æ®åº“è¿æ¥")

        try:
            # ç¡®ä¿ä½¿ç”¨æ­£ç¡®çš„åŒæ­¥æ•°æ®åº“ URL
            sync_db_url = DB_URL
            if "postgresql+asyncpg://" in DB_URL:
                sync_db_url = DB_URL.replace("postgresql+asyncpg://", "postgresql://", 1)
            elif "postgresql://" not in DB_URL and "postgres://" not in DB_URL:
                raise DatabaseException(f"ä¸æ”¯æŒçš„æ•°æ®åº“ URL æ ¼å¼: {DB_URL}")
            
            self.engine = create_engine(sync_db_url)
            self.SessionLocal = sessionmaker(bind=self.engine)
        except Exception as e:
            raise DatabaseException(f"æ•°æ®åº“è¿æ¥å¤±è´¥ï¼Œè¯·æ£€æŸ¥ DATABASE_URLï¼š{e}") from e

    def get_session(self):
        self._ensure_engine()
        return self.SessionLocal()

    def _init_db(self):
        """
        åˆå§‹åŒ–æ•°æ®åº“ï¼šåˆ›å»ºæ‰€æœ‰è¡¨ç»“æ„
        å¦‚æœè¡¨å·²å­˜åœ¨åˆ™è·³è¿‡ï¼Œä¸ä¼šåˆ é™¤ç°æœ‰æ•°æ®
        """
        self._ensure_engine()

        # å¯ç”¨ pgvector æ‰©å±•
        with self.engine.connect() as conn:
            try:
                conn.execute(text("CREATE EXTENSION IF NOT EXISTS vector"))
                conn.commit()
            except Exception as e:
                raise DatabaseException(
                    f"åˆå§‹åŒ– pgvector æ‰©å±•å¤±è´¥ï¼Œè¯·ç¡®è®¤æ•°æ®åº“å·²å®‰è£… pgvector: {e}"
                ) from e
        
        # åˆ›å»ºæ‰€æœ‰è¡¨
        Base.metadata.create_all(self.engine)
        logger.info("Database tables initialized successfully")

    # --- ğŸ“ˆ 1. è‚¡ä»·ç¼“å­˜é€»è¾‘ ---

    @monitor
    def get_cached_prices(self, ticker: str, start_date: str, end_date: str) -> pd.DataFrame:
        """
        å°è¯•ä»æ•°æ®åº“è·å–è‚¡ä»·æ•°æ®ï¼Œè¿”å› Pandas DataFrame (ä¸ yfinance æ ¼å¼å…¼å®¹)
        """
        start = datetime.strptime(start_date, "%Y-%m-%d")
        end = datetime.strptime(end_date, "%Y-%m-%d")

        with self.get_session() as session:
            stmt = select(StockPrice).where(
                StockPrice.ticker == ticker,
                StockPrice.date >= start,
                StockPrice.date <= end
            ).order_by(StockPrice.date)
            results = session.scalars(stmt).all()

            if not results:
                return pd.DataFrame()

            # è½¬æ¢ä¸º DataFrame
            data = [{
                "Date": r.date,
                "Open": r.open,
                "High": r.high,
                "Low": r.low,
                "Close": r.close,
                "Volume": r.volume
            } for r in results]
            
            df = pd.DataFrame(data)
            df.set_index("Date", inplace=True)
            return df

    @monitor
    def save_stock_data(self, ticker: str, df: pd.DataFrame, source: str = "yfinance"):
        """
        å°† DataFrame æ ¼å¼çš„ K çº¿æ•°æ®å­˜å…¥æ•°æ®åº“ (Upsert)
        """
        if df.empty: return

        records = []
        for date, row in df.iterrows():
            # å…¼å®¹ DataFrame index ä¸º date çš„æƒ…å†µ
            ts = date if isinstance(date, datetime) else pd.to_datetime(date)
            records.append({
                "ticker": ticker,
                "date": ts,
                "open": float(row["Open"]),
                "high": float(row["High"]),
                "low": float(row["Low"]),
                "close": float(row["Close"]),
                "volume": float(row["Volume"]),
                "source": source,
                "resolution": "1d"
            })

        if not records: return

        with self.get_session() as session:
            # ä½¿ç”¨ Postgres çš„ ON CONFLICT DO NOTHING (é¿å…é‡å¤æŠ¥é”™)
            stmt = pg_insert(StockPrice).values(records)
            stmt = stmt.on_conflict_do_nothing(
                index_elements=['ticker', 'date', 'resolution']
            )
            session.execute(stmt)
            session.commit()
            logger.info(f"[DB] Cached {len(records)} price records for {ticker}")

    # --- ğŸ“ 2. æŠ¥å‘Šå½’æ¡£é€»è¾‘ ---

    def save_analysis_report(self, run_id: str, ticker: str, role: str, content: str, report_type: str = "analysis", embedding: List[float] = None):
        """ä¿å­˜åˆ†æå¸ˆæŠ¥å‘Šæˆ–æœ€ç»ˆå†³ç­–
        
        Args:
            run_id: æœ¬æ¬¡è¿è¡Œçš„å”¯ä¸€æ ‡è¯†
            ticker: è‚¡ç¥¨ä»£ç 
            role: Agent è§’è‰²åç§°
            content: æŠ¥å‘Šå†…å®¹
            report_type: æŠ¥å‘Šç±»å‹ï¼Œå¯é€‰å€¼: 'analysis'(åˆ†æ), 'plan'(è®¡åˆ’), 'critique'(è¯„è®º)
            embedding: å‘é‡åµŒå…¥
        """
        with self.get_session() as session:
            report = AnalysisReport(
                run_id=run_id,
                ticker=ticker,
                agent_role=role,
                report_type=report_type,
                content=content,
                embedding=embedding,
                date=datetime.now()
            )
            session.add(report)
            session.commit()
            logger.debug(f"Archived report for {role} (type: {report_type})")

    # --- ğŸ§  3. è®°å¿†é€»è¾‘ (å·²å®ç°) ---

    def save_lesson(self, situation: str, advice: str, embedding: List[float]):
        """ä¿å­˜ä¸€æ¡ç»éªŒæ•™è®­"""
        with self.get_session() as session:
            lesson = TradingLesson(
                situation=situation,
                outcome_advice=advice,
                embedding=embedding
            )
            session.add(lesson)
            session.commit()

    def search_similar_lessons(self, query_embedding: List[float], limit: int = 3) -> List[TradingLesson]:
        """
        å‘é‡æœç´¢ï¼šæŸ¥æ‰¾æœ€ç›¸ä¼¼çš„å†å²ç»éªŒ
        ä½¿ç”¨ä½™å¼¦ç›¸ä¼¼åº¦ (Cosine Similarity)
        """
        self._ensure_engine()
        with self.get_session() as session:
            # ä½¿ç”¨ cosine_distance æ’åº (pgvector ä¸­çš„ <=> æ“ä½œç¬¦)
            # 1 - cosine_distance = cosine_similarity
            stmt = select(TradingLesson).order_by(
                TradingLesson.embedding.cosine_distance(query_embedding)
            ).limit(limit)
            
            return session.scalars(stmt).all()

    def get_latest_insider_sentiment(self, ticker: str, max_age_days: int = 90) -> Optional[Dict[str, Any]]:
        with self.get_session() as session:
            cutoff_date = datetime.now() - timedelta(days=max_age_days)
            stmt = (
                select(InsiderActivity)
                .where(
                    InsiderActivity.ticker == ticker,
                    InsiderActivity.activity_type == "sentiment",
                    InsiderActivity.created_at >= cutoff_date,
                )
                .order_by(InsiderActivity.created_at.desc())
                .limit(1)
            )
            result = session.scalars(stmt).first()

            if not result:
                return None

            return {
                "ticker": result.ticker,
                "activity_type": result.activity_type,
                "sentiment_score": result.sentiment_score,
                "raw_data": result.raw_data,
                "source": result.source,
                "created_at": result.created_at.isoformat() if result.created_at else None,
            }

    def save_insider_sentiment(self, ticker: str, sentiment_score: Optional[float], raw_data: Dict[str, Any], source: str = "finnhub") -> None:
        with self.get_session() as session:
            record = InsiderActivity(
                ticker=ticker,
                activity_type="sentiment",
                sentiment_score=sentiment_score,
                raw_data=raw_data,
                source=source,
                created_at=datetime.now(),
            )
            session.add(record)
            session.commit()

    # --- ğŸ“ 4. åŸºæœ¬é¢æ•°æ®é€»è¾‘ ---
    
    @monitor
    def get_cached_fundamentals(self, ticker: str, max_age_days: int = 1) -> Optional[Dict[str, Any]]:
        """
        ä»æ•°æ®åº“è·å–ç¼“å­˜çš„åŸºæœ¬é¢æ•°æ®
        
        Args:
            ticker: è‚¡ç¥¨ä»£ç 
            max_age_days: æœ€å¤§å¹´é¾„(å¤©)ï¼Œè¶…è¿‡æ­¤å¹´é¾„çš„æ•°æ®ä¸è¿”å›
            
        Returns:
            åŸºæœ¬é¢æ•°æ®å­—å…¸æˆ– None
        """
        with self.get_session() as session:
            cutoff_date = datetime.now() - timedelta(days=max_age_days)
            
            stmt = select(FundamentalData).where(
                FundamentalData.ticker == ticker,
                FundamentalData.created_at >= cutoff_date
            ).order_by(FundamentalData.created_at.desc()).limit(1)
            
            result = session.scalars(stmt).first()
            
            if not result:
                return None
            
            # è½¬æ¢ä¸ºå­—å…¸
            return {
                "company_name": result.company_name,
                "sector": result.sector,
                "industry": result.industry,
                "country": result.country,
                "exchange": result.exchange,
                "market_cap": result.market_cap,
                "pe_ratio": result.pe_ratio,
                "forward_pe": result.forward_pe,
                "pb_ratio": result.pb_ratio,
                "dividend_yield": result.dividend_yield,
                "beta": result.beta,
                "week_52_high": result.week_52_high,
                "week_52_low": result.week_52_low,
                "current_ratio": result.current_ratio,
                "debt_to_equity": result.debt_to_equity,
                "return_on_equity": result.return_on_equity,
                "profit_margins": result.profit_margins,
                "raw_data": result.raw_data,
                "source": result.source,
                "data_date": result.data_date,
            }
    
    @monitor
    def save_fundamentals(self, ticker: str, data: Dict[str, Any], source: str = "yfinance", data_date: Optional[datetime] = None):
        """
        ä¿å­˜åŸºæœ¬é¢æ•°æ®åˆ°æ•°æ®åº“
        
        Args:
            ticker: è‚¡ç¥¨ä»£ç 
            data: åŸºæœ¬é¢æ•°æ®å­—å…¸
            source: æ•°æ®æ¥æº
            data_date: æ•°æ®æ—¥æœŸ(é»˜è®¤ä»Šå¤©)
        """
        if not data:
            return
        
        if data_date is None:
            data_date = datetime.now()
        
        with self.get_session() as session:
            record = {
                "ticker": ticker,
                "data_date": data_date,
                "company_name": data.get("company_name") or data.get("longName"),
                "sector": data.get("sector"),
                "industry": data.get("industry"),
                "country": data.get("country"),
                "exchange": data.get("exchange"),
                "market_cap": data.get("market_cap") or data.get("marketCap"),
                "pe_ratio": data.get("pe_ratio") or data.get("trailingPE"),
                "forward_pe": data.get("forward_pe") or data.get("forwardPE"),
                "pb_ratio": data.get("pb_ratio") or data.get("priceToBook"),
                "dividend_yield": data.get("dividend_yield") or data.get("dividendYield"),
                "beta": data.get("beta"),
                "week_52_high": data.get("week_52_high") or data.get("fiftyTwoWeekHigh"),
                "week_52_low": data.get("week_52_low") or data.get("fiftyTwoWeekLow"),
                "current_ratio": data.get("current_ratio") or data.get("currentRatio"),
                "debt_to_equity": data.get("debt_to_equity") or data.get("debtToEquity"),
                "return_on_equity": data.get("return_on_equity") or data.get("returnOnEquity"),
                "profit_margins": data.get("profit_margins") or data.get("profitMargins"),
                "raw_data": data,  # ä¿å­˜å®Œæ•´åŸå§‹æ•°æ®
                "source": source,
            }
            
            stmt = pg_insert(FundamentalData).values(record)
            stmt = stmt.on_conflict_do_update(
                index_elements=['ticker', 'data_date', 'source'],
                set_={
                    "company_name": stmt.excluded.company_name,
                    "sector": stmt.excluded.sector,
                    "industry": stmt.excluded.industry,
                    "market_cap": stmt.excluded.market_cap,
                    "pe_ratio": stmt.excluded.pe_ratio,
                    "raw_data": stmt.excluded.raw_data,
                    "updated_at": datetime.now(),
                }
            )
            session.execute(stmt)
            session.commit()
            logger.info(f"[DB] Saved fundamentals for {ticker} from {source}")


# =============================================================================
# FastAPI Dependency Injection Helper (Sync)
# =============================================================================

def get_sync_db_session():
    """
    FastAPI dependency for database session (sync version).
    
    Usage:
        @router.get("/items")
        def get_items(db: Session = Depends(get_sync_db_session)):
            ...
    """
    db_manager = DBManager()
    session = db_manager.get_session()
    try:
        yield session
    finally:
        session.close()


# =============================================================================
# Async Database Session Support
# =============================================================================

_async_engine = None
_async_session_factory = None


def _get_async_db_url() -> str:
    """Convert sync DB URL to async URL for asyncpg."""
    if not DB_URL:
        raise ValueError("DATABASE_URL not set")
    
    # Convert postgresql:// to postgresql+asyncpg://
    if DB_URL.startswith("postgresql://"):
        return DB_URL.replace("postgresql://", "postgresql+asyncpg://", 1)
    elif DB_URL.startswith("postgres://"):
        return DB_URL.replace("postgres://", "postgresql+asyncpg://", 1)
    elif "asyncpg" in DB_URL:
        return DB_URL
    else:
        raise ValueError(f"Unsupported database URL format: {DB_URL}")


def _ensure_async_engine():
    """Lazily create async engine and session factory."""
    global _async_engine, _async_session_factory
    
    if _async_engine is None:
        async_url = _get_async_db_url()
        _async_engine = create_async_engine(
            async_url,
            echo=False,
            pool_pre_ping=True,
            pool_size=20,      # å¢åŠ è¿æ¥æ± å¤§å°
            max_overflow=40,    # å¢åŠ æº¢å‡ºè¿æ¥æ•°
            pool_recycle=3600,   # 1å°æ—¶åå›æ”¶è¿æ¥ï¼ˆé˜²æ­¢è¿æ¥è¿‡æœŸï¼‰
            pool_timeout=30,     # è·å–è¿æ¥è¶…æ—¶30ç§’
            connect_args={}  # Keep empty for asyncpg compatibility
        )
        _async_session_factory = async_sessionmaker(
            bind=_async_engine,
            class_=AsyncSession,
            expire_on_commit=False
        )


@asynccontextmanager
async def get_db_session() -> AsyncGenerator[AsyncSession, None]:
    """
    Async context manager for database session.
    
    Usage:
        async with get_db_session() as session:
            result = await session.execute(select(Model))
            ...
    """
    _ensure_async_engine()
    
    async with _async_session_factory() as session:
        try:
            yield session
        except Exception:
            await session.rollback()
            raise
        finally:
            await session.close()
