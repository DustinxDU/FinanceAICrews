# CLAUDE.md

This file provides guidance to Claude Code (claude.ai/code) when working with code in this repository.

## Project Overview

FinanceAICrews is a multi-agent financial analysis platform built on CrewAI, featuring collaborative AI agents for stock analysis (fundamental, technical, sentiment) with multi-LLM support, MCP protocol integration for data sources, and a 3-layer subscription-based market data architecture.

**Core Philosophy**: "Code is Engine, Config is Soul" - Variable logic (prompts, workflows, thresholds) belongs in config/DB, not hardcoded.

## Essential Commands

### Backend Development
```bash
# Start backend (FastAPI)
source venv/bin/activate
python -m backend.app.main

# Run tests
pytest tests/
```

### Frontend Development
```bash
cd frontend
npm install           # Install dependencies
npm run dev          # Development mode (port 3000)
npm run build        # Production build
```

### Database Migrations
```bash
alembic revision --autogenerate -m "description"
alembic upgrade head
```

### Docker Deployment
```bash
# Start all services
docker compose up -d

# Or start core services only
docker compose up -d db redis
```

## Architecture Overview

### 3-Layer Data Architecture
```
Layer 1: assets            â†’ Basic info (ticker, name, sector, exchange)
         â†“ Subscription sync
Layer 2: realtime_quotes   â†’ Live snapshots (price, volume, 5min updates)
         â†“ Daily archival
Layer 3: market_prices     â†’ Historical OHLCV data (for agent analysis)
```

### Project Structure

```
FinanceAICrews/
â”œâ”€â”€ AICrews/                    # ðŸ”µ Agent Engine & Business Logic
â”‚   â”œâ”€â”€ application/crew/       #    Crew assembly, preflight checks
â”‚   â”œâ”€â”€ services/              #    Business services (analysis, sync)
â”‚   â”œâ”€â”€ tools/                 #    Tool implementations + registry
â”‚   â”œâ”€â”€ llm/                   #    Unified LLM management
â”‚   â”œâ”€â”€ infrastructure/        #    MCP, Redis, Jobs, Storage
â”‚   â”œâ”€â”€ database/              #    DBManager, Models
â”‚   â””â”€â”€ schemas/               #    Pydantic v2 schemas (shared)
â”‚
â”œâ”€â”€ backend/                   # ðŸŸ¡ FastAPI API Layer
â”‚   â””â”€â”€ app/
â”‚       â”œâ”€â”€ api/v1/endpoints/  #    REST endpoints (thin)
â”‚       â”œâ”€â”€ ws/                #    WebSocket routes
â”‚       â””â”€â”€ core/lifespan.py   #    Startup/shutdown
â”‚
â”œâ”€â”€ frontend/                  # ðŸ”´ Next.js Frontend
â”‚   â”œâ”€â”€ app/                   #    Pages (App Router)
â”‚   â”œâ”€â”€ components/            #    Reusable components
â”‚   â””â”€â”€ lib/api.ts             # client
â”‚
â”œâ”€â”€ config/                    # âšª YAML Configuration
â”‚   â”œâ”€â”€ agents/                #    Agent personas, tasks, crews
â”‚   â”œâ”€â”€ llm/                   #    LLM provider configs
â”‚   â””â”€â”€ prompts/               #    Prompt templates
â”‚
â””â”€â”€ docker/mcp/                # ðŸŸ£ MCP Data Servers
    â”œâ”€â”€ akshare/               #    A-share (China) market data
    â””â”€â”€ yfinance/              #    US/Global market data
```

### Key Entry Points

- `AICrews/runner.py`: Config-driven crew execution
- `AICrews/application/crew/assembler.py`: Assembles CrewAI from DB config
- `AICrews/llm/unified_manager.py`: Unified LLM access point
- `backend/app/main.py`: FastAPI app entry
- `frontend/app/layout.tsx`: Root layout

## Development Guidelines

### Layer Separation
- **Backend** (`backend/`): API orchestration ONLY - keep endpoints thin
- **AICrews** (`AICrews/`): Business logic, services, tools
- **Frontend** (`frontend/`): Presentation layer

### Configuration First
- **Don't hardcode** agent personas, task flows, or thresholds
- **Do configure** via `config/agents/*.yaml` or DB updates

### Schema Management
- **All schemas** go in `AICrews/schemas/*` (Pydantic v2)
- Import schemas from `AICrews.schemas.*`

### Tool Development
When adding tools (`AICrews/tools/*`):
1. Input validation: Validate ticker, date ranges, limits
2. Timeout/retry: All external I/O must have timeouts
3. Serializable output: Return JSON-compatible types
4. Error handling: Don't leak secrets/stack traces
5. Register: Add to `AICrews/tools/registry/tool_registry.py`

### Database Access
```python
# Sync context
from AICrews.database.db_manager import DBManager
db = DBManager()
with db.get_session() as session:
    # Your code
    session.commit()

# Async context (in endpoints)
from backend.app.security import get_db
async def endpoint(db: Session = Depends(get_db)):
    # Your code
```

### LLM Usage
- **Always use** `AICrews.llm.unified_manager` - no direct SDK calls
- **Never hardcode** API keys - use environment variables

## URLs & Ports

- **Frontend**: http://localhost:3000
- **Backend API**: http://localhost:8000
- **API Docs**: http://localhost:8000/n- **Database**: localhost:5432
- **Redis**: localhost:6379

## Code Style

### Python
- Type hints required
- Google-style docstrings
- PEP 8 compliant

### TypeScript
- Prefer `interface` over `type`
- Strict mode enabled
- Avoid `any`

---

**License**: MIT
